{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.style as style\n",
    "style.use('seaborn-whitegrid')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import SGD\n",
    "from PIL import Image\n",
    "from keras import models, layers\n",
    "\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_avg(image, aWeight):\n",
    "    global bg\n",
    "    # initialize the background\n",
    "    if bg is None:\n",
    "        bg = image.copy().astype(\"float\")\n",
    "        return\n",
    "\n",
    "    # compute weighted average, accumulate it and update the background\n",
    "    cv2.accumulateWeighted(image, bg, aWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(image, threshold=25):\n",
    "    global bg\n",
    "    # find the absolute difference between background and current frame\n",
    "    diff = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
    "\n",
    "    # threshold the diff image so that we get the foreground\n",
    "    thresholded = cv2.threshold(diff,\n",
    "                                threshold,\n",
    "                                255,\n",
    "                                cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # get the contours in the thresholded image\n",
    "    (_, cnts, _) = cv2.findContours(thresholded.copy(),\n",
    "                                    cv2.RETR_EXTERNAL,\n",
    "                                    cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # return None, if no contours detected\n",
    "    if len(cnts) == 0:\n",
    "        return\n",
    "    else:\n",
    "        # based on contour area, get the maximum contour which is the hand\n",
    "        segmented = max(cnts, key=cv2.contourArea)\n",
    "        return (thresholded, segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # initialize weight for running average\n",
    "    aWeight = 0.5\n",
    "\n",
    "    # get the reference to the webcam\n",
    "    camera = cv2.VideoCapture(0)\n",
    "\n",
    "    # region of interest (ROI) coordinates\n",
    "    top, right, bottom, left = 10, 350, 225, 590\n",
    "\n",
    "    # initialize num of frames\n",
    "    num_frames = 0\n",
    "\n",
    "    # keep looping, until interrupted\n",
    "    while(True):\n",
    "        # get the current frame\n",
    "        (grabbed, frame) = camera.read()\n",
    "\n",
    "        # resize the frame\n",
    "        frame = imutils.resize(frame, width=700)\n",
    "\n",
    "        # flip the frame so that it is not the mirror view\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # clone the frame\n",
    "        clone = frame.copy()\n",
    "\n",
    "        # get the height and width of the frame\n",
    "        (height, width) = frame.shape[:2]\n",
    "\n",
    "        # get the ROI\n",
    "        roi = frame[top:bottom, right:left]\n",
    "\n",
    "        # convert the roi to grayscale and blur it\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "        # to get the background, keep looking till a threshold is reached\n",
    "        # so that our running average model gets calibrated\n",
    "        if num_frames < 30:\n",
    "            run_avg(gray, aWeight)\n",
    "        else:\n",
    "            # segment the hand region\n",
    "            hand = segment(gray)\n",
    "\n",
    "            # check whether hand region is segmented\n",
    "            if hand is not None:\n",
    "                # if yes, unpack the thresholded image and\n",
    "                # segmented region\n",
    "                (thresholded, segmented) = hand\n",
    "\n",
    "                # draw the segmented region and display the frame\n",
    "                cv2.drawContours(clone, [segmented + (right, top)], -1, (0, 0, 255))\n",
    "                cv2.imshow(\"Thesholded\", thresholded)\n",
    "\n",
    "        # draw the segmented hand\n",
    "        cv2.rectangle(clone, (left, top), (right, bottom), (0,255,0), 2)\n",
    "\n",
    "        # increment the number of frames\n",
    "        num_frames += 1\n",
    "\n",
    "        # display the frame with segmented hand\n",
    "        cv2.imshow(\"Video Feed\", clone)\n",
    "\n",
    "        # observe the keypress by the user\n",
    "        keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the user pressed \"q\", then stop looping\n",
    "        if keypress == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "# free up memory\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 240)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f21f3839454b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# free up memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "bg = None\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Function - To find the running average over the background\n",
    "#-------------------------------------------------------------------------------\n",
    "def run_avg(image, aWeight):\n",
    "    global bg\n",
    "    # initialize the background\n",
    "    if bg is None:\n",
    "        bg = image.copy().astype(\"float\")\n",
    "        return\n",
    "\n",
    "    # compute weighted average, accumulate it and update the background\n",
    "    cv2.accumulateWeighted(image, bg, aWeight)\n",
    "\n",
    "    #-------------------------------------------------------------------------------\n",
    "    # Function - To segment the region of hand in the image\n",
    "    #-------------------------------------------------------------------------------\n",
    "    def segment(image, threshold=5):\n",
    "        global bg\n",
    "        # find the absolute difference between background and current frame\n",
    "        diff = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
    "\n",
    "        # threshold the diff image so that we get the foreground\n",
    "        thresholded = cv2.threshold(diff,\n",
    "                                    threshold,\n",
    "                                    255,\n",
    "                                    cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        # get the contours in the thresholded image\n",
    "        (_, cnts, _) = cv2.findContours(thresholded.copy(),\n",
    "                                        cv2.RETR_EXTERNAL,\n",
    "                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # return None, if no contours detected\n",
    "        if len(cnts) == 0:\n",
    "            return\n",
    "        else:\n",
    "            # based on contour area, get the maximum contour which is the hand\n",
    "            segmented = max(cnts, key=cv2.contourArea)\n",
    "            return (thresholded, segmented)\n",
    "\n",
    "            #-------------------------------------------------------------------------------\n",
    "            # Main function\n",
    "            #-------------------------------------------------------------------------------\n",
    "            if __name__ == \"__main__\":\n",
    "                # initialize weight for running average\n",
    "                aWeight = 0.5\n",
    "\n",
    "                # get the reference to the webcam\n",
    "                camera = cv2.VideoCapture(0)\n",
    "\n",
    "                # region of interest (ROI) coordinates\n",
    "                top, right, bottom, left = 10, 350, 225, 590\n",
    "\n",
    "                # initialize num of frames\n",
    "                num_frames = 90\n",
    "\n",
    "                # keep looping, until interrupted\n",
    "                while(True):\n",
    "                    # get the current frame\n",
    "                    (grabbed, frame) = camera.read()\n",
    "\n",
    "                    # resize the frame\n",
    "                    frame = imutils.resize(frame, width=700)\n",
    "\n",
    "                    # flip the frame so that it is not the mirror view\n",
    "                    frame = cv2.flip(frame, 1)\n",
    "\n",
    "                    # clone the frame\n",
    "                    clone = frame.copy()\n",
    "\n",
    "                    # get the height and width of the frame\n",
    "                    (height, width) = frame.shape[:2]\n",
    "\n",
    "                    # get the ROI\n",
    "                    roi = frame[top:bottom, right:left]\n",
    "\n",
    "                    # convert the roi to grayscale and blur it\n",
    "                    \n",
    "                    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "                    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "                    # to get the background, keep looking till a threshold is reached\n",
    "                    # so that our running average model gets calibrated\n",
    "                    if num_frames < 30:\n",
    "                        run_avg(gray, aWeight)\n",
    "                    else:\n",
    "                        # segment the hand region\n",
    "                        hand = segment(gray)\n",
    "\n",
    "                        # check whether hand region is segmented\n",
    "                        if hand is not None:\n",
    "                            # if yes, unpack the thresholded image and\n",
    "                            # segmented region\n",
    "                            (thresholded, segmented) = hand\n",
    "\n",
    "                            # draw the segmented region and display the frame\n",
    "                            cv2.drawContours(clone, [segmented + (right, top)], -1, (0, 0, 255))\n",
    "                            cv2.imshow(\"Thresholded\", thresholded)\n",
    "\n",
    "                    # draw the segmented hand\n",
    "                    cv2.rectangle(clone, (left, top), (right, bottom), (0,255,0), 2)\n",
    "\n",
    "                    # increment the number of frames\n",
    "                    num_frames += 1\n",
    "\n",
    "                    # display the frame with segmented hand\n",
    "                    cv2.imshow(\"Video Feed\", clone)\n",
    "\n",
    "                    # observe the keypress by the user\n",
    "                    keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "                    # if the user pressed \"q\", then stop looping\n",
    "                    if keypress == ord(\"q\"):\n",
    "                        break\n",
    "\n",
    "            # free up memory\n",
    "            camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393, 700, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=False, history=500)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    \n",
    "    cv2.imshow('frame',fgmask)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# both MOG and MOG2 can be used, with different parameter values\n",
    "backgroundSubtractor = cv2.BackgroundSubtractorMOG()\n",
    "\n",
    "#backgroundSubtractor = cv2.BackgroundSubtractorMOG(history=100, nmixtures=5, backgroundRatio=0.7, noiseSigma=0)\n",
    "#backgroundSubtractor = cv2.BackgroundSubtractorMOG2(history=500, varThreshold=500)\n",
    "#backgroundSubtractor = cv2.BackgroundSubtractorMOG2()\n",
    "\n",
    "# apply the algorithm for background images using learning rate > 0\n",
    "for i in range(1, 16):\n",
    "    bgImageFile = \"data/backgrounds/bg_%03d.jpg\" % i\n",
    "    print \"Opening background\", bgImageFile\n",
    "    bg = cv2.imread(bgImageFile)\n",
    "    backgroundSubtractor.apply(bg, learningRate=0.5)\n",
    "\n",
    "# apply the algorithm for detection image using learning rate 0\n",
    "stillFrame = cv2.imread(\"data/test_bg.jpg\")\n",
    "fgmask = backgroundSubtractor.apply(stillFrame, learningRate=0)\n",
    "\n",
    "# show both images\n",
    "cv2.imshow(\"original\", cv2.resize(stillFrame, (0, 0), fx=0.5, fy=0.5))\n",
    "cv2.imshow(\"mask\", cv2.resize(fgmask, (0, 0), fx=0.5, fy=0.5))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), activation='relu', input_shape=(224, 224,1))) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to convert raw images to arrays, predict with Keras model, and return\n",
    "#### name of predicted gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_from_single_image(path):\n",
    "    '''\n",
    "    Takes in a path to a single image, returns it in an array\n",
    "    that can be fed into the Keras model.\n",
    "    '''\n",
    "    x_data = []\n",
    "    count = 0\n",
    "    img = Image.open(path).convert('L')\n",
    "    img = img.resize((224, 224))\n",
    "    arr = np.array(img)\n",
    "    x_data.append(arr) \n",
    "    count = count + 1\n",
    "    return np.array(x_data, dtype = 'float32').reshape((count, 224, 224, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_array_from_single_image('images_to_predict/black_background.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_point(arr):\n",
    "    '''Takes in properly formatted Keras array,\n",
    "    returns an array with predicted gesture.\n",
    "    '''\n",
    "    return model.predict(arr, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    }
   ],
   "source": [
    "b = predict_single_point(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_gesture_name(prediction):\n",
    "    y = model.predict(prediction, batch_size=1, verbose=1)\n",
    "    return gesture_names_2[np.where(y[0] == max(y[0]))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_names = {0: 'thumb',\n",
    "                 1: 'palm_moved',\n",
    "                 2: 'l',\n",
    "                 3: 'palm',\n",
    "                 4: 'ok',\n",
    "                 5: 'down',\n",
    "                 6: 'index',\n",
    "                 7: 'c',\n",
    "                 8: 'fist',\n",
    "                 9: 'fist_moved'}\n",
    "\n",
    "gesture_names_2 = {0: '05_thumb',\n",
    "                 1: '08_palm_moved',\n",
    "                 2: '02_l',\n",
    "                 3: '01_palm',\n",
    "                 4: '07_ok',\n",
    "                 5: '10_down',\n",
    "                 6: '06_index',\n",
    "                 7: '09_c',\n",
    "                 8: '03_fist',\n",
    "                 9: '04_fist_moved'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'09_c'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gesture_names_2[np.where(b[0] == max(b[0]))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'09_c'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_gesture_name(get_array_from_single_image('images_to_predict/black_background.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open images_to_predict/frame_00_06_0016.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
